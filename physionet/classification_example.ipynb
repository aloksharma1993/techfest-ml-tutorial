{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Classification\n",
    "\n",
    "Classification is a form of supervised learning where the outcome is a discrete *class*. For example, a message in your inbox can be classified as *email* or *spam*. A handwritten digit recognizer outputs one of 10 possible classes, one for each digit (0-9).\n",
    "\n",
    "As our example, we'll be predicting mortality of Intensive Care Unit (CU) patients. The dataset is from the [2012 PhysioNet/Computing in Cardiology challenge](http://physionet.org/challenge/2012/). The dataset contains records of ICU stays of more than 48 hours. At the start of the stay, several static attributes such as age, gender and height are recorded for the patient. Then over the next 48 hours, various medical measurements were taken, some more than once. The outcome we want to predict is whether the patient survived or died in-hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The raw dataset can be found on the challenge website linked above. However, for this tutorial, we did a little preprocessing for you so we spend less time on data munging. If you want to know more about what we did, see the Feature Engineering section at the bottom of the tutorial.\n",
    "\n",
    "We provide a [training set](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv) and a [test set](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/test-a.csv). The data is stored as a CSV, with a header labelling the attributes. Let's load the training set by using the `requests` library to download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv')\n",
    "print response.status_code\n",
    "raw_data = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `csv.reader()` expects a file-like object as the argument, we wrap the downloaded data in a `StringIO` object, which provides the methods `csv.reader()` expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import StringIO\n",
    "\n",
    "f = StringIO.StringIO(raw_data)\n",
    "data = []\n",
    "reader = csv.reader(f)\n",
    "header = reader.next()\n",
    "for row in reader:\n",
    "    row = [float(r) for r in row]\n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of attributes do we have in our dataset? Let's print the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALP_diff', 'ALP_first', 'ALP_last', 'ALP_max', 'ALP_mean', 'ALP_min', 'ALT_diff', 'ALT_first', 'ALT_last', 'ALT_max', 'ALT_mean', 'ALT_min', 'AST_diff', 'AST_first', 'AST_last', 'AST_max', 'AST_mean', 'AST_min', 'Age', 'Albumin_diff', 'Albumin_first', 'Albumin_last', 'Albumin_max', 'Albumin_mean', 'Albumin_min', 'BUN_diff', 'BUN_first', 'BUN_last', 'BUN_max', 'BUN_mean', 'BUN_min', 'Bilirubin_diff', 'Bilirubin_first', 'Bilirubin_last', 'Bilirubin_max', 'Bilirubin_mean', 'Bilirubin_min', 'Cholesterol_diff', 'Cholesterol_first', 'Cholesterol_last', 'Cholesterol_max', 'Cholesterol_mean', 'Cholesterol_min', 'Creatinine_diff', 'Creatinine_first', 'Creatinine_last', 'Creatinine_max', 'Creatinine_mean', 'Creatinine_min', 'DiasABP_diff', 'DiasABP_first', 'DiasABP_last', 'DiasABP_max', 'DiasABP_mean', 'DiasABP_min', 'FiO2_diff', 'FiO2_first', 'FiO2_last', 'FiO2_max', 'FiO2_mean', 'FiO2_min', 'GCS_diff', 'GCS_first', 'GCS_last', 'GCS_max', 'GCS_mean', 'GCS_min', 'Gender', 'Glucose_diff', 'Glucose_first', 'Glucose_last', 'Glucose_max', 'Glucose_mean', 'Glucose_min', 'HCO3_diff', 'HCO3_first', 'HCO3_last', 'HCO3_max', 'HCO3_mean', 'HCO3_min', 'HCT_diff', 'HCT_first', 'HCT_last', 'HCT_max', 'HCT_mean', 'HCT_min', 'HR_diff', 'HR_first', 'HR_last', 'HR_max', 'HR_mean', 'HR_min', 'Height', 'ICUType', 'K_diff', 'K_first', 'K_last', 'K_max', 'K_mean', 'K_min', 'Lactate_diff', 'Lactate_first', 'Lactate_last', 'Lactate_max', 'Lactate_mean', 'Lactate_min', 'MAP_diff', 'MAP_first', 'MAP_last', 'MAP_max', 'MAP_mean', 'MAP_min', 'MechVent_diff', 'MechVent_first', 'MechVent_last', 'MechVent_max', 'MechVent_mean', 'MechVent_min', 'Mg_diff', 'Mg_first', 'Mg_last', 'Mg_max', 'Mg_mean', 'Mg_min', 'NIDiasABP_diff', 'NIDiasABP_first', 'NIDiasABP_last', 'NIDiasABP_max', 'NIDiasABP_mean', 'NIDiasABP_min', 'NIMAP_diff', 'NIMAP_first', 'NIMAP_last', 'NIMAP_max', 'NIMAP_mean', 'NIMAP_min', 'NISysABP_diff', 'NISysABP_first', 'NISysABP_last', 'NISysABP_max', 'NISysABP_mean', 'NISysABP_min', 'Na_diff', 'Na_first', 'Na_last', 'Na_max', 'Na_mean', 'Na_min', 'PaCO2_diff', 'PaCO2_first', 'PaCO2_last', 'PaCO2_max', 'PaCO2_mean', 'PaCO2_min', 'PaO2_diff', 'PaO2_first', 'PaO2_last', 'PaO2_max', 'PaO2_mean', 'PaO2_min', 'Platelets_diff', 'Platelets_first', 'Platelets_last', 'Platelets_max', 'Platelets_mean', 'Platelets_min', 'RespRate_diff', 'RespRate_first', 'RespRate_last', 'RespRate_max', 'RespRate_mean', 'RespRate_min', 'SaO2_diff', 'SaO2_first', 'SaO2_last', 'SaO2_max', 'SaO2_mean', 'SaO2_min', 'SysABP_diff', 'SysABP_first', 'SysABP_last', 'SysABP_max', 'SysABP_mean', 'SysABP_min', 'Temp_diff', 'Temp_first', 'Temp_last', 'Temp_max', 'Temp_mean', 'Temp_min', 'TroponinI_diff', 'TroponinI_first', 'TroponinI_last', 'TroponinI_max', 'TroponinI_mean', 'TroponinI_min', 'TroponinT_diff', 'TroponinT_first', 'TroponinT_last', 'TroponinT_max', 'TroponinT_mean', 'TroponinT_min', 'Urine_diff', 'Urine_first', 'Urine_last', 'Urine_max', 'Urine_mean', 'Urine_min', 'WBC_diff', 'WBC_first', 'WBC_last', 'WBC_max', 'WBC_mean', 'WBC_min', 'Weight_diff', 'Weight_first', 'Weight_last', 'Weight_max', 'Weight_mean', 'Weight_min', 'pH_diff', 'pH_first', 'pH_last', 'pH_max', 'pH_mean', 'pH_min', 'In-hospital_death']\n"
     ]
    }
   ],
   "source": [
    "print header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have fields like `Age`, `Gender`, `ICUType` and `Height` which only have one value, and then we have a bunch of fields with `FIELDNAME_min`, `FIELDNAME_max`, `FIELDNAME_mean`, etc. This is how we decided to handle the time series measurements. For each medical metric, we computed the min, max, mean, first value, last value and difference between first and last values as a way to represent measurements over time. The fields themselves are explained in more detail in the [Physionet website](http://physionet.org/challenge/2012/).\n",
    "\n",
    "The outcome is the last field: `In-hospital_death`. 1 means the patient died in the hospital. 0 means the patient survived.\n",
    "\n",
    "Not all of the metrics were measured for each patient. Missing values are represented by -1. All recorded values are nonnegative.\n",
    "\n",
    "Let's separate the features from the outcome and store them in `numpy` arrays. `numpy` is a library useful for scientific computing, and it defines array objects for storing scientific data and many mathematical functions. `scikit-learn`, the Python machine learning library we'll be using in this tutorial, is designed to work well with data in `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "features = numpy.array([f[0:-1] for f in data])\n",
    "labels = numpy.array([f[-1] for f in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "\n",
    "How do we begin understanding our dataset? A good place to start is by measuring the proportion of positive outcomes. The proportion of positive outcomes is just the mean of the labels. Since we put our data into numpy arrays, we can take advantage of some [very useful methods on arrays](http://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145625\n"
     ]
    }
   ],
   "source": [
    "print labels.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion is fairly low (as would hopefully be expected with modern medicine!).\n",
    "\n",
    "TODO: Next, let's see if there are any correlations with age or ICUType.??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model\n",
    "\n",
    "`Scikit-learn` uses a common API for all their machine learning models, which makes it really easy to try different models. Let's start with a simple logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# in training set: 2560\n"
     ]
    }
   ],
   "source": [
    "num_train = int(0.8 * len(features))\n",
    "print '# in training set:', num_train\n",
    "X_train = features[0:num_train]\n",
    "y_train = labels[0:num_train]\n",
    "X_test = features[num_train:-1]\n",
    "y_test = labels[num_train:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression is a linear model that is then passed through the logit function. Because it's a linear model, it won't handle missing values represented by -1 very well. Scikit-learn has an `Imputer` class that provides basic strategies for filling in, or imputing, missing values. Let's use the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X_train_imputed = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are also sensitive to different ranges for input features. For example, if one input features has a range of -1 to 1 and another has a range of 0 to 100, the feature with the larger range will disproportionately influence the model. (TODO: verify?) To combat this, we scale all the features to **zero mean and unit variance**, using scikit-learn's `StandardScaler` class.\n",
    "\n",
    "Note: We filled in missing values before scaling, otherwise the number used to represent missing values would distort the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we're ready to train the model. Scikit-learn's models all have a `fit()` function to fit the model to the training data and a `predict()` function to predict the outcome on new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "Now that we have a model, how do we tell how good it is? Since we have outcomes to compare predictions to, we can quantitatively measure how well the model is doing. This is where we use the test set. Because we only used the training set to develop the model, we can use the test set to see how well the model works on unseen data. With classification, each outcome is either predicted correctly or not, so the measure of success is binary.\n",
    "\n",
    "Models in scikit-learn usually have a `score()` method, which takes in a set of features and their labels. For logistic regression, this method returns the **accuracy** of the model on the input data. Accuracy is the number of outcomes correctly predicted divided by the total number of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560250391236307"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(imp.transform(X_test))\n",
    "model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from before that the proportion of positive outcomes is fairly low. This means that accuracy is not necessarily a very useful metric of model performance. A model which predicts survival for each patient (a negative outcome) would still be ~86% accurate! Thankfully, there are other metrics for model performance:\n",
    "* **recall**, also known as **sensitivity**: of the patients who died, how many did we predict correctly\n",
    "* **precision**, also known as **positive predictivity**: of the patients we predicted positive, what fraction was correct\n",
    "\n",
    "One method of visualizing these metrics is to plot the precision-recall curve. As precision goes down, recall tends to go up. For example, we can achieve 100% recall if we predict everyone as positive, but this means our precision is 14.5% (the proportion of true positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line enables IPython's matplotlib mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngRWeGN8AYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c9d507f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted_probs = model.predict_proba(X_test_scaled)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predicted_probs[:,1])\n",
    "plt.plot(precision, recall, 's-', lw=1)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One measure of model performance (and the method used in the Physionet challenge) is the minimum of precision and recall. One would pick the point in the curve that maximizes this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max min of P/Se 0.505376344086\n"
     ]
    }
   ],
   "source": [
    "both = zip(precision, recall)\n",
    "print 'Max min of P/Se', max([min(r) for r in both])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should I talk about roc curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.821605993164\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGuI4tBcicgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c9d436990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "print 'AUC', roc_auc_score(y_test, predicted_probs[:,1])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predicted_probs[:,1])\n",
    "plt.plot(fpr, tpr, 's-', lw=1)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "The logistic regression model takes in a hyperparameter *C* that controls the regularization. Regularization is the method of introducing constraints to a solution to prevent overfitting. In logistic regression, the type of regularization used is usually a penalty on very large coefficients. *C* controls the amount of penalty incurred. So how do we pick the best *C* for our dataset? For that matter, how do we know logistic regression is even the model we should use?\n",
    "\n",
    "Well, we can try all of the various possibilities and evaluate the solution on a test set. The model that gives the best results is the winner. However, we don't want to use our test set for this selection process because we then won't have any unseen data to make a final evaluation. We need a *third* partition to our dataset set to evaluate the model, referred to as the \"validation set\". Instead of creating a fixed third partition as the validation set, we usually choose to use the method of **cross-validation.** This uses different splits of the training set for train and evaluation.\n",
    "\n",
    "Scikit-learn has a library of utilities for cross-validation and performance evaluation in the `sklearn.cross-validation module`. It has several classes which automatically generate different splits of the training set. We will be using the `StratifiedKFold` iterator, which splits the data into *n* folds. *n - 1* folds are used for training, and the *nth* fold is used for test. A stratified K-fold maintains approximately the same percentage of each outcome class in each fold as in the complete set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max min of P/Se 0.34328358209\n",
      "Max min of P/Se 0.34693877551\n",
      "Max min of P/Se 0.404255319149\n",
      "Max min of P/Se 0.510638297872\n",
      "Max min of P/Se 0.382978723404\n",
      "Max min of P/Se 0.425531914894\n",
      "Max min of P/Se 0.521739130435\n",
      "Max min of P/Se 0.45652173913\n",
      "Max min of P/Se 0.509803921569\n",
      "Max min of P/Se 0.458333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "skf = StratifiedKFold(labels, 10)\n",
    "for train, test in skf:\n",
    "    X_train = features[train]\n",
    "    y_train = labels[train]\n",
    "    X_test = features[test]\n",
    "    y_test = labels[test]\n",
    "    \n",
    "    imp = Imputer(missing_values=-1, strategy='mean')\n",
    "    X_train_imputed = imp.fit_transform(X_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    X_test_scaled = scaler.transform(imp.transform(X_test))\n",
    "    predicted_probs = model.predict_proba(X_test_scaled)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, predicted_probs[:,1])\n",
    "    both = zip(precision, recall)\n",
    "    print 'Max min of P/Se', max([min(r) for r in both])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we actually search for the best value of C? The traditional method is **grid search**, where you exhaustively try all the parameter combinations until the best model is found. More efficient methods have been developed over the years. Scikit-learn has several different implementations of parameter search algorithms in the `sklearn.grid_search` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Test Set\n",
    "\n",
    "So far, we haven't touched the test set. This was intentional, so that you have a pristine dataset to test your final model on after we went through all the topics above. Try loading the data on your own from [https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv) and evaluating your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Raw data is not a nice csv. How did we preprocess the data?\n",
    "\n",
    "We only used the training set from the challenge because that's the only labelled dataset available to the public.\n",
    "\n",
    "The featurization code can be found on [github](https://github.secureserver.net/lgu/techfest-ml-tutorial/blob/master/physionet/create_featurized_datasets.py). Each patient record was read and stored as a dictionary of metric name to list of measurements. Then for each metric name, we computed the min, max, mean, first value, last value and difference between first and last values. If no measurements were recorded for that metric, all of those features would be -1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
