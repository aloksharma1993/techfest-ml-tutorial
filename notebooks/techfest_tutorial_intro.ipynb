{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# ML Tutorial by\n",
    "\n",
    "### Lydia Gu, David Kellogg, Arsen Mamikonyan\n",
    "\n",
    "Using scikit-learn and ipython notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## TODO list for this presentation\n",
    "\n",
    "bold = No drawing involved\n",
    "\n",
    "- modify supervised learning figure to have last label as \"??\" (ask Lydia)\n",
    "- modify unsupervised learning figure to have last label as \"??\" (ask Lydia)\n",
    "- \"How is ML done\" drawing (ask Lydia, explain thoroughly, or try drawing yourself)\n",
    "- **What did we decide for challenge problems?**\n",
    "- **Best practices slide, I'm not sure I agree**\n",
    "- new drawing - overfitting vs underfitting (find a drawing online?)\n",
    "- new drawing - bias vs variance?? (not sure how...)\n",
    "- new drawing - data transformation (raw data one side -> arrow a matrix of values)\n",
    "- **fix variance vs bias slide & notes**\n",
    "- **scikit-learn reference**\n",
    "- **classification & regression metrics definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Machine Learning ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Machine learning is learning from data\n",
    "- We have a lot of data and we use mathematics to learn something about the structure and patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Combine\n",
    "\n",
    "- (a lot of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- mathematics (and computational power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **Machine learning explores the construction and study of algorithms that can learn from and make predictions on data.**\n",
    "> \n",
    "> *Ron Kohavi; Foster Provost (1998). \"Glossary of terms\". Machine Learning 30: 271–274.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some Machine Learning Examples #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Machine Learning example 1\n",
    "\n",
    "\n",
    "### Facebooks personalizes your newsfeed based on your likes and clicks\n",
    "\n",
    "<img class=\"small-10\" src=\"media/facebook_newsfeed.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Facebook uses your online behavior, e.g.\n",
    "\n",
    "- how often you click on posts from your friends\n",
    "- how often you talk to them on facebook\n",
    "- how often you like their posts\n",
    "- how often you comment on their posts\n",
    "\n",
    "And shows you only posts that you are more likely to be interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Machine Learning example 2\n",
    "\n",
    "### Netflix shows you suggestions based on what you have watched and other netflix users have watched\n",
    "\n",
    "<img class=\"small-10\" src=\"media/netflix_recs.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Netflix uses your behavior, e.g.\n",
    "\n",
    "- Movies you watch\n",
    "- (Does netflix have access to your friends list?)\n",
    "\n",
    "They predict which movies you are likely going to like based on your past/recent movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Machine Learning example 3\n",
    "\n",
    "### Siri\n",
    "\n",
    "<img class=\"small-10\" src=\"media/siri.jpg\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Siri uses ML to understand what are you saying\n",
    "\n",
    "Siri uses ML to answer the questions you ask\n",
    "\n",
    "It does so by mining the internet for data and structuring it using various ML techniques which they Apple doesn't tell us much about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised vs. Unsupervised Learning #\n",
    "\n",
    "**Supervised Learning** - Training data is labeled\n",
    "\n",
    "**Unsupervised Learning** - Training data is not labeled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can separate Machine Learning into two big parts\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised Learning\n",
    "\n",
    "- Labeled training data\n",
    "- Unlabeled data to answer questions on\n",
    "\n",
    "<img class=\"small-12 columns\" src=\"media/supervised learning.png\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Supervised Learning is learning from labeled data\n",
    "\n",
    "- Start with a bunch of emails that we know which ones are spam\n",
    "- predict which out of future emails are spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "- Unlabeled data to learn from\n",
    "- Unlabeled data to answer questions on\n",
    "\n",
    "<img class=\"small-12 columns\" src=\"media/unsupervised learning.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Unsupervided Learning is learning without much guidlines\n",
    "\n",
    "- We have a bunch of emails that we don't know if they are spam\n",
    "- We try to group those into spam and not spam\n",
    "\n",
    "Deep Learning is a type of unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning #\n",
    "\n",
    "- Labeled data (to learn on)\n",
    "- Unlabeled data (to answer our question for)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Multiple techniques for supervised learning, we can devide them into 2 groups\n",
    "\n",
    "- Classification\n",
    "- Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Supervised Learning #\n",
    " In supervised learning, we typically have an outcome (for example, a stock price) that we want to predict from a set of input features (for example, previous stock price, company financial data). We use a set of input­outcome mappings to build a model that will predict the outcome on new, unseen input values.\n",
    " \n",
    "If the output is continuous, e.g. stock price, the problem is referred to as a regression problem. This is shown by the image on the right side of the figure below. The x­axis is a continuous input feature (ex. previous stock price), and the y­axis is some continuous output (ex. future stock price). The example fits a simple linear model to the data. If the output is categorical, e.g. is email or spam, the problem is referred to as a classification problem. This is shown by the image on the left side of the figure below. The x and y­axes are continuous input features (ex. age and education level), and the outcome is one of two classes (ex. employed/not employed). The model is a decision boundary, the dotted line, where on one side, the outcome is one class, and on the other, it is the other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Classification vs Regression\n",
    "\n",
    "##### Regression\n",
    "- labels are continuous\n",
    "    * what will be stock pice (tomorrow after closing)\n",
    "    * temperature in Phoenix (tomorrow at noon)\n",
    "\n",
    "##### Classification\n",
    "- labels are categorical\n",
    "    * Which will be the best talk at the Techfest?\n",
    "    * Will there be a good vegeterian option at lunch?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The email example we talked about falls into classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regresssion\n",
    "\n",
    "**Data: **\n",
    "Price listings of houses in Greater Boston Area.\n",
    "\n",
    "**Question:**\n",
    "What is the market value of a 900 square feet apartment?\n",
    "\n",
    "\n",
    "<img class=\"small-10 columns\" src=\"media/regression.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "**Data:**\n",
    "Price listings of houses in Greater Boston Area.\n",
    "\n",
    "**Question:**\n",
    "Does the apartment have a good view?\n",
    "\n",
    "<img class=\"small-10 columns\" src=\"media/classification.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "We have\n",
    "\n",
    "- only unlabbeled data\n",
    "\n",
    "Goal\n",
    "\n",
    "- deduce some structure of the data and predict (is this true?) based on that data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "no outcome data. The goal is instead to learn about the structure of the data\n",
    "\n",
    "- **clustering:** grouping the input data into clusters, e.g. FILLME\n",
    "- **density estimation:** estimating a probability distribution for the data\n",
    "- **dimension reduction:** finding a lower-dimensional representation of the input data. This is often used for data visualization for FILLME\n",
    "\n",
    "**Unsupervised Learning is more challenging we won't talk much about that in this tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Unsupervised Learning Examples\n",
    "\n",
    "- clustering\n",
    "- density estimation\n",
    "- dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This tutorial #\n",
    "\n",
    "- Supervised learning methods\n",
    "- use scikit-learn [FILLME: Reference] to show you examples\n",
    "- challenge problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- We will spend most of the tutorial talking about Supervised Learning\n",
    "- Scikit-learn is a collection of useful machine learning tools, from the models themselves to tools for cleaning data and evaluating models.\n",
    "- FILLME: What did we decide for challenge problems?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How is ML done\n",
    "\n",
    "<img class=\"small-11\" src=\"https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcT8TqGzN7vGVBzw2O5iAG-luBv92jL6ngtJJvf6VyJ8qyq98Aru\" />\n",
    "\n",
    "1. Get data\n",
    "2. Clean data\n",
    "3. Data Transformation (feature engineering)\n",
    "4. Fit a model (Data Mining)\n",
    "5. Evaluate your model\n",
    "5. (Deploy your model)\n",
    "6. Use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "1. **Get data** collect data from multiple sources, feed it into the program\n",
    "2. **Clean data** most data doesn't have same interpretation, or is missing values\n",
    "3. **Data Transformation (feature engineering)** construct features \n",
    "4. **Fit a model (Data Mining)** train your algorithm on the data\n",
    "5. **Evaluate your model** figure out if your model is working\n",
    "5. **(Deploy your model)** deploy to your production server\n",
    "5. **Use the model** you rock!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Today we will cover\n",
    "\n",
    "1. Get data\n",
    "2. Clean data\n",
    "3. **Data Transformation (feature engineering)**\n",
    "4. **Fit a model (Data Mining)**\n",
    "5. **Evaluate your model**\n",
    "5. (Deploy your model)\n",
    "6. **Use the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Transformation (Feature Engineering) #\n",
    "\n",
    "<img class=\"small-12 columns\" src=\"media/data_transformation.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Your data is not a neatly organized matrix of values, such as what we’ve given you here.\n",
    "- You need to extract features from your data, based on intuition about what would be predictive features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why can't we use original data?\n",
    "\n",
    "- It could be **scattered**. We need to **consolidate** the data\n",
    "- computer can't interpret the raw data. We have to guide it, transform the data into machine understandable format (construct features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Your data could be scattered across different databases\n",
    "- computer can't understand scanned leasing agreement in a same way it understands JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are features?\n",
    "\n",
    "- Each feature is a value that represents a transformation applied to a data point\n",
    "- Features could be both discrete and continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Read from examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Example features\n",
    "\n",
    "- What is the distance of the apartment from the river in feet?\n",
    "- Does the apartment have south facing windows?\n",
    "- What is the area of the apartment?\n",
    "- Value of a picture in an image\n",
    "- number of logins in past day, number of distinct page visits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Transformation Best Practices\n",
    "\n",
    "- Normalize your features\n",
    "    * Some models might have problems if you have different type of features\n",
    "    * e.g. if feature 1 is in range (0, 1) don't have feature 2 be in range (0, 1000)\n",
    "- Careful with categorical inputs\n",
    "    * Arsen (I'm not sure I agree with this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "After feature extraction, features often require some preprocessing to be properly used in numerical models:\n",
    "- data normalization: scaling data to between 0 and 1 or ­1 and 1. Features are normalized so that features with a wide range (ex. ­10000 to 10000) don’t skew the model to undervalue features with small ranges (ex. 0 to 0.1)\n",
    "- categorical inputs: How do we convert categorical inputs (for example, WebsiteBuilder account type: Personal, Business, Business Plus) to numerical values for use in a model? We can’t just assign increasing integers 0, 1 and 2 because this implies there is some order to the categories, which is typically not the case. Instead, we need to create N ­ 1 input features, where N is the number of categories in the categorical input. Each input features is a boolean, in this example is_personal and is_business. Only N ­ 1 features are needed because if all are false, then the value is Nth category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a model\n",
    "\n",
    "- A [mathematical] **Model** is the algorithm that we want to use to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To generalize data we break up the data into training and test sets\n",
    "- The training set is used to train the model, and the test set is used to evaluate the model performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## scikit-learn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = clf.fit(digits.data[:-1], digits.target[:-1])\n",
    "clf.predict(digits.data[-1])  # Predicting with a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- very simple api: `.fit` to fit a model to data\n",
    "    * give target (second argument) if  supervised learning\n",
    "- `.predict` to predict a value for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9d53804e50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDSREsIGECDaQ0P8B/jLlFrdmZv4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d579068d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Her you can see the image we predicted the value for\n",
    "- 64 features: brighnesses of 64 pixels in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation/Chosing a model\n",
    "\n",
    "- How do we know if a model is “doing well”?\n",
    "- no one solution fits all\n",
    "- we might have different objectives\n",
    "- assume training data is very close to data we want to use the model on\n",
    "- split chunck of data to test our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- differnt types of models are designed to work better with different types of problems / different types of data\n",
    "- We want to \"simulate\" predicting with classifier as close as to a real world situation when evaluating the classifier\n",
    "- We randomly split training data into train/test and use test to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross validation\n",
    "\n",
    "- A technique to make sure that your model works, before appling to real world situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is the most basic technique with which you can't go wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### k-fold cross validation\n",
    "\n",
    "1. We randomly split data into K sets\n",
    "1. for each of K sets\n",
    "    2. We train a model on the remaining K-1 sets\n",
    "    2. We test if the model works on K-th set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### scikit-learn example\n",
    "\n",
    "scikit-learn has built-in functions for doing k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Also there is a helper for splitting data *manually*\n",
    "```\n",
    "from sklearn.cross_validation import train_test_split\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(digits.data, digits.target, test_size=0.2)\n",
    "```\n",
    "Numbers are accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97527473,  0.95027624,  0.98328691,  0.99159664,  0.95774648])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(clf, digits.data, digits.target, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### What do these numbers mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Classification metrics\n",
    "- accuracy  (This gets reported by `cross_val_score`)\n",
    "    * \\# of outcomes correctly predicted / total # of outcomes\n",
    "    * This is a good metric when we care about REPLACE_ME\n",
    "- precision\n",
    "    * \\# of correctly predicted in a class / total # in that class\n",
    "    * If we care about REPLACE_ME\n",
    "- recall\n",
    "    * \\# of REPLACE_ME\n",
    "    * REPLACE_ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Other metrics:\n",
    "- f1, roc auc\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regression metrics\n",
    "\n",
    "- mean squared error\n",
    "    * average of the square of the difference between the predicted and the true outcome.\n",
    "- r2 score\n",
    "    * REPLACE_ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "It's hard to interprete all these metrics, here are some concepts that help you understand which one you should use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Underfitting vs. Overfitting\n",
    "\n",
    "<img class=\"small-10 columns\" src=\"media/overfitting_underfitting.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**underfitting** - you have too general model, it lacks parameters to be able to tune\n",
    "\n",
    "e.g. you have too **few** trees in your random forest\n",
    "\n",
    "**overfitting** - your model has too many parameters to tune\n",
    "\n",
    "e.g. you have too **many** trees in your random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias vs. Variance\n",
    "\n",
    "Bias - erroneous assumptions in the learning algorithm\n",
    "\n",
    "Variance - error from sensitivity to small fluctuations in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "FILLME - consult Wikipedia for explanations\n",
    "Bias refers to error caused by picking an overly simple model that can’t fully fit the training data. Variance is the difference between the training set error and test set error. (From wikipedia http://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff):\n",
    "- The bias is error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
    "- The variance is error from sensitivity to small fluctuations in the training set. High variance can cause overfitting: modeling the random noise in the training data, rather than the intended outputs.\n",
    "When selecting and training a model, how do we know if we have high bias or high variance?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
