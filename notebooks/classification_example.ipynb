{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Classification\n",
    "\n",
    "Classification is a form of supervised learning where the outcome is a discrete *class*. For example, a message in your inbox can be classified as *email* or *spam*. A handwritten digit recognizer outputs one of 10 possible classes, one for each digit (0-9).\n",
    "\n",
    "Let's use machine learning to predict mortality of Intensive Care Unit (ICU) patients. The dataset we'll be looking at is from the [2012 PhysioNet/Computing in Cardiology challenge](http://physionet.org/challenge/2012/). It contains records of ICU stays longer than 48 hours. At the start of the stay, several static attributes such as age, gender and height are recorded for the patient. Then over the next 48 hours, various medical measurements are taken, some more than once. The outcome we want to predict is whether the patient survived or died in-hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The raw dataset can be found on the challenge website linked above. However, for this tutorial, we did a little preprocessing for you, so we spend less time on data munging. If you want to know more about what we did, see the [Feature Engineering](#Feature-Engineering) section at the bottom of the tutorial.\n",
    "\n",
    "We provide a [training set](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv) and a [test set](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/test-a.csv). The data is stored as a CSV, with a header labelling the attributes. Let's load the training set by using the `requests` library to download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/train-a.csv')\n",
    "print response.status_code\n",
    "raw_data = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `csv.reader()` expects a file-like object as the argument, we wrap the downloaded data in a `StringIO` object, which provides the methods `csv.reader()` expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import StringIO\n",
    "\n",
    "f = StringIO.StringIO(raw_data)\n",
    "data = []\n",
    "reader = csv.reader(f)\n",
    "feature_names = reader.next()\n",
    "for row in reader:\n",
    "    row = [float(r) for r in row]\n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of attributes do we have in our dataset? Let's print the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALP_diff', 'ALP_first', 'ALP_last', 'ALP_max', 'ALP_mean', 'ALP_min', 'ALT_diff', 'ALT_first', 'ALT_last', 'ALT_max', 'ALT_mean', 'ALT_min', 'AST_diff', 'AST_first', 'AST_last', 'AST_max', 'AST_mean', 'AST_min', 'Age', 'Albumin_diff', 'Albumin_first', 'Albumin_last', 'Albumin_max', 'Albumin_mean', 'Albumin_min', 'BUN_diff', 'BUN_first', 'BUN_last', 'BUN_max', 'BUN_mean', 'BUN_min', 'Bilirubin_diff', 'Bilirubin_first', 'Bilirubin_last', 'Bilirubin_max', 'Bilirubin_mean', 'Bilirubin_min', 'Cholesterol_diff', 'Cholesterol_first', 'Cholesterol_last', 'Cholesterol_max', 'Cholesterol_mean', 'Cholesterol_min', 'Creatinine_diff', 'Creatinine_first', 'Creatinine_last', 'Creatinine_max', 'Creatinine_mean', 'Creatinine_min', 'DiasABP_diff', 'DiasABP_first', 'DiasABP_last', 'DiasABP_max', 'DiasABP_mean', 'DiasABP_min', 'FiO2_diff', 'FiO2_first', 'FiO2_last', 'FiO2_max', 'FiO2_mean', 'FiO2_min', 'GCS_diff', 'GCS_first', 'GCS_last', 'GCS_max', 'GCS_mean', 'GCS_min', 'Gender', 'Glucose_diff', 'Glucose_first', 'Glucose_last', 'Glucose_max', 'Glucose_mean', 'Glucose_min', 'HCO3_diff', 'HCO3_first', 'HCO3_last', 'HCO3_max', 'HCO3_mean', 'HCO3_min', 'HCT_diff', 'HCT_first', 'HCT_last', 'HCT_max', 'HCT_mean', 'HCT_min', 'HR_diff', 'HR_first', 'HR_last', 'HR_max', 'HR_mean', 'HR_min', 'Height', 'ICUType', 'K_diff', 'K_first', 'K_last', 'K_max', 'K_mean', 'K_min', 'Lactate_diff', 'Lactate_first', 'Lactate_last', 'Lactate_max', 'Lactate_mean', 'Lactate_min', 'MAP_diff', 'MAP_first', 'MAP_last', 'MAP_max', 'MAP_mean', 'MAP_min', 'MechVent_diff', 'MechVent_first', 'MechVent_last', 'MechVent_max', 'MechVent_mean', 'MechVent_min', 'Mg_diff', 'Mg_first', 'Mg_last', 'Mg_max', 'Mg_mean', 'Mg_min', 'NIDiasABP_diff', 'NIDiasABP_first', 'NIDiasABP_last', 'NIDiasABP_max', 'NIDiasABP_mean', 'NIDiasABP_min', 'NIMAP_diff', 'NIMAP_first', 'NIMAP_last', 'NIMAP_max', 'NIMAP_mean', 'NIMAP_min', 'NISysABP_diff', 'NISysABP_first', 'NISysABP_last', 'NISysABP_max', 'NISysABP_mean', 'NISysABP_min', 'Na_diff', 'Na_first', 'Na_last', 'Na_max', 'Na_mean', 'Na_min', 'PaCO2_diff', 'PaCO2_first', 'PaCO2_last', 'PaCO2_max', 'PaCO2_mean', 'PaCO2_min', 'PaO2_diff', 'PaO2_first', 'PaO2_last', 'PaO2_max', 'PaO2_mean', 'PaO2_min', 'Platelets_diff', 'Platelets_first', 'Platelets_last', 'Platelets_max', 'Platelets_mean', 'Platelets_min', 'RespRate_diff', 'RespRate_first', 'RespRate_last', 'RespRate_max', 'RespRate_mean', 'RespRate_min', 'SaO2_diff', 'SaO2_first', 'SaO2_last', 'SaO2_max', 'SaO2_mean', 'SaO2_min', 'SysABP_diff', 'SysABP_first', 'SysABP_last', 'SysABP_max', 'SysABP_mean', 'SysABP_min', 'Temp_diff', 'Temp_first', 'Temp_last', 'Temp_max', 'Temp_mean', 'Temp_min', 'TroponinI_diff', 'TroponinI_first', 'TroponinI_last', 'TroponinI_max', 'TroponinI_mean', 'TroponinI_min', 'TroponinT_diff', 'TroponinT_first', 'TroponinT_last', 'TroponinT_max', 'TroponinT_mean', 'TroponinT_min', 'Urine_diff', 'Urine_first', 'Urine_last', 'Urine_max', 'Urine_mean', 'Urine_min', 'WBC_diff', 'WBC_first', 'WBC_last', 'WBC_max', 'WBC_mean', 'WBC_min', 'Weight_diff', 'Weight_first', 'Weight_last', 'Weight_max', 'Weight_mean', 'Weight_min', 'pH_diff', 'pH_first', 'pH_last', 'pH_max', 'pH_mean', 'pH_min', 'In-hospital_death']\n"
     ]
    }
   ],
   "source": [
    "print feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa, that's a lot of variable names! Let's take a closer look. We have fields like `Age`, `Gender`, `ICUType` and `Height`, which only have one value, and then we have a bunch of fields with `FIELDNAME_min`, `FIELDNAME_max`, `FIELDNAME_mean`, etc. This is how we decided to handle the time series measurements. For each medical metric, we computed the min, max, mean, first value, last value and difference between first and last values as a way to represent measurements over time. That's why there are so many fields! The medical measurements themselves are explained in more detail on the [Physionet website](http://physionet.org/challenge/2012/).\n",
    "\n",
    "The outcome is the last field: `In-hospital_death`. 1 means the patient died in the hospital. 0 means the patient survived.\n",
    "\n",
    "Not all of the metrics were measured for each patient. Missing values are represented by -1. All recorded values are nonnegative.\n",
    "\n",
    "Let's separate the features from the outcome and store them in `numpy` arrays. `numpy` is a library useful for scientific computing, and it defines array objects for storing scientific data, as well as many mathematical functions. `scikit-learn`, the Python machine learning library we'll be using in this tutorial, is designed to work well with data in `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = numpy.array([f[0:-1] for f in data])  # features\n",
    "y = numpy.array([f[-1] for f in data])  # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "\n",
    "How do we begin understanding our dataset? A good place to start is by measuring the proportion of positive outcomes. The proportion of positive outcomes is just the mean of the labels, since labels are either 0 or 1. Since we put our data into numpy arrays, we can take advantage of some [very useful methods on arrays](http://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145625\n"
     ]
    }
   ],
   "source": [
    "print y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportion is fairly low (as would hopefully be expected with modern medicine!).\n",
    "\n",
    "Let's use [matplotlib](http://matplotlib.org/api/) and the [histogram function](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist) to visualize some of the features.\n",
    "\n",
    "The following line enables IPython's matplotlib mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE6VJREFUeJzt3X2MXfdd5/H3p0kNTcvWtViNH1EsiFc1Arbd1jwL75L1\nhqpr+6/ESCCrjfgnQFOkLbEjQfwXSyMBRVrlj4W2GiJi1lvAcrRd1ZO0owUhNS11IM3E2F7tQMat\nx31+AAG28t0/7hl8M7HnXs/Tvfbv/ZJGPud3Hu73Hnk+87vn/M49qSokSbe31426AEnS2jPsJakB\nhr0kNcCwl6QGGPaS1ADDXpIaMDDskxxN8mKSF5I8leQ7kmxKMpXkXJLTSTYuWv98krNJ9q1t+ZKk\nYWSpcfZJ7gY+Cby1qv4pyf8APg58P/Dlqno8ySPAW6rqSJLdwFPAO4FtwDPArqp6ZW3fhiRpKYN6\n9t8ErgB3JbkTuAv4ArAfmOzWmQQOdtMHgONVdaWqZoELwJ7VLlqSdHOWDPuq+irwW8Df0Qv5r1fV\nFDBRVfPdavPARDe9FZjr28UcvR6+JGmElgz7JN8LvB+4m16QvynJz/WvU73zQEt954LfxyBJI3bn\ngOXvAP6iqr4CkORPgB8FLiXZXFWXkmwBLnfrXwR29G2/vWt7lST+AZCkZaiqLGe7QWF/Fvi1JG8A\n/hG4F3gO+HvgMPDB7t+T3fqngKeS/Da90zf3dOuvWsG3myTHqurYqOsYBx6LazwW13gsrllJR3nJ\nsK+qv0ryB8BngVeAzwH/Hfgu4ESSB4FZ4P5u/ZkkJ4AZ4CrwUPm1mpI0coN69lTV48Dji5q/Sq+X\nf731fwP4jZWXJklaLd5BO3rToy5gjEyPuoAxMj3qAsbI9KgLuB0seVPVmr1oUp6zl6Sbs5LstGcv\nSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1YOC3Xkpq0zg9\nZMjv0lo5w17SEsYh78351eBpHElqgGEvSQ0w7CWpAYa9JDVgYNgn+TdJzvT9fCPJ+5JsSjKV5FyS\n00k29m1zNMn5JGeT7FvbtyBJGuSmHkuY5HXARWAP8MvAl6vq8SSPAG+pqiNJdgNPAe8EtgHPALuq\n6pW+/fhYQmnM9YZejsdoHPOiZz0fS3gvcKGqXgb2A5Nd+yRwsJs+AByvqitVNQtcoPfHQZI0Ijcb\n9oeA4930RFXNd9PzwEQ3vRWY69tmjl4PX5I0IkOHfZINwH8G/ufiZdU7F7TU571x+CwoSc26mTto\nfwb4y6r6Ujc/n2RzVV1KsgW43LVfBHb0bbe9a3uVJMf6ZqeravomapGk216SvcDeVdnXsBdok/wR\n8L+rarKbfxz4SlV9MMkRYOOiC7R7uHaB9vuq74W8QCuNPy/Qjp+VZOdQYZ/kjcDfAjur6ltd2ybg\nBPA9wCxwf1V9vVv2KPBe4CrwcFV9YrUKlrQ+DPvxs+Zhv9oMe2n8GfbjZz2HXkqSbkGGvSQ1wLCX\npAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lq\ngGEvSQ0w7CWpAYa9JDXAsJekBgwV9kk2JvlYkpeSzCT54SSbkkwlOZfkdJKNfesfTXI+ydkk+9au\nfEnSMIbt2f8u8PGqeivwg8BZ4AgwVVW7gGe7eZLsBh4AdgP3AU8k8ROEJI3QwBBO8mbgJ6vqIwBV\ndbWqvgHsBya71SaBg930AeB4VV2pqlngArBntQuXJA1vmB73TuBLST6a5HNJfi/JG4GJqprv1pkH\nJrrprcBc3/ZzwLZVq1iSdNPuHHKdtwO/VFWfSfIhulM2C6qqktQS+3jNsiTH+manq2p6iFokqRlJ\n9gJ7V2Nfw4T9HDBXVZ/p5j8GHAUuJdlcVZeSbAEud8svAjv6tt/etb1KVR1bdtXSbW5A50mN6DrB\n0wvzSR5b7r4GnsapqkvAy0l2dU33Ai8CTwOHu7bDwMlu+hRwKMmGJDuBe4Dnllug1K4a8Y9uJ8P0\n7AF+GfjDJBuA/wu8B7gDOJHkQWAWuB+gqmaSnABmgKvAQ1Xl/xxJGqGMIoeTVFVl3V9YukX0TuOM\nuo8URl8DQDAvelaSnY5/l6QGGPaS1ADDXpIaYNhLUgMMe0lqwLBDLyVpZMbhJrNbfUSQYS/pFjDq\nrL+lcx7wNI4kNcGwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktQA\nw16SGjBU2CeZTfLXSc4kea5r25RkKsm5JKeTbOxb/2iS80nOJtm3VsVLkoYzbM++gL1V9baq2tO1\nHQGmqmoX8Gw3T5LdwAPAbuA+4IkkfoKQpBG6mRBe/B2f+4HJbnoSONhNHwCOV9WVqpoFLgB7kCSN\nzM307J9J8tkkv9C1TVTVfDc9D0x001uBub5t54BtK65UkrRswz685Mer6otJ/jUwleRs/8KqqgFP\nknnNsiTH+manq2p6yFokqQlJ9gJ7V2NfQ4V9VX2x+/dLSf6U3mmZ+SSbq+pSki3A5W71i8COvs23\nd22L93lsJYVLa2UcHoEnAXSd4OmF+SSPLXdfA0/jJLkryXd1028E9gEvAKeAw91qh4GT3fQp4FCS\nDUl2AvcAzy23QGk0asQ/0uoapmc/AfxpkoX1/7CqTif5LHAiyYPALHA/QFXNJDkBzABXgYeqyv+9\nkjRCGUUOJ6lb/Untun31TuOMun8SrGHBONQRxiGzVpKdjn+XpAYY9pLUAMNekhpg2EtSAwx7SWqA\nYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2\nktQAw16SGjBU2Ce5I8mZJE9385uSTCU5l+R0ko196x5Ncj7J2ST71qpwSdLwhu3ZPwzMcO2pv0eA\nqaraBTzbzZNkN/AAsBu4D3giiZ8eJGnEBgZxku3Au4Dfp/eYd4D9wGQ3PQkc7KYPAMer6kpVzQIX\ngD2rWbAk6eYN0+v+HeADwCt9bRNVNd9NzwMT3fRWYK5vvTlg20qLlCStzJ1LLUzybuByVZ1Jsvd6\n61RVJanrLVtY5Qb7PtY3O11V00uXKklt6XJ372rsa8mwB34M2J/kXcB3Av8qyZPAfJLNVXUpyRbg\ncrf+RWBH3/bbu7bXqKpjK6pckm5zXSd4emE+yWPL3deSp3Gq6tGq2lFVO4FDwCer6ueBU8DhbrXD\nwMlu+hRwKMmGJDuBe4DnllucJGl1DOrZL7ZwSuY3gRNJHgRmgfsBqmomyQl6I3euAg9V1VKneCRJ\n6yCjyOIkVVUZvKa0/nrXoEbdRwnWsGAc6gjjkFkryU7HwEtSAwx7SWqAYS9JDTDsJakBhr0kNcCw\nl6QGGPaS1ADDXpIaYNhLUgNu9usSpDUz4NtTJa2AYa8xMw55P/K74qVV52kcSWqAYS9JDTDsJakB\nhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgOWDPsk35nk00meTzKT5L927ZuSTCU5l+R0ko192xxNcj7J\n2ST71voNSJIGG/jA8SR3VdU/JLkT+HPgvwD7gS9X1eNJHgHeUlVHkuwGngLeCWwDngF2VdUri/bp\nA8f1GuPxoG8YlwdcW8OCcaijgQeOV9U/dJMbgDuAr9EL+8mufRI42E0fAI5X1ZWqmgUuAHuWU5gk\nafUMDPskr0vyPDAPfKqqXgQmqmq+W2UemOimtwJzfZvP0evhS5JGaOAXoXWnYP5tkjcDn0jy7xct\nrwHfVnjdZUmO9c1OV9X04HIlqR1J9gJ7V2NfQ3/rZVV9I8n/Av4dMJ9kc1VdSrIFuNytdhHY0bfZ\n9q7tevs7trySJakNXSd4emE+yWPL3deg0TjfvTDSJskbgP8InAFOAYe71Q4DJ7vpU8ChJBuS7ATu\nAZ5bbnGSpNUxqGe/BZhM8jp6fxierKpnk5wBTiR5EJgF7geoqpkkJ4AZ4CrwUA0a7iNJWnMDh16u\nyYs69FLX4dBLa7i+caijgaGXkqRbn2EvSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJ\naoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBA8M+yY4kn0ry\nYpLPJ3lf174pyVSSc0lOJ9nYt83RJOeTnE2yby3fgCRpsIEPHE+yGdhcVc8neRPwl8BB4D3Al6vq\n8SSPAG+pqiNJdgNPAe8EtgHPALuq6pW+ffrAcb2GDxy3husbhzoaeOB4VV2qque76W8DL9EL8f3A\nZLfaJL0/AAAHgONVdaWqZoELwJ7lFCdJWh03dc4+yd3A24BPAxNVNd8tmgcmuumtwFzfZnP0/jhI\nkkbkzmFX7E7h/DHwcFV9K7n2SaKqqvcR/IZesyzJsb7Z6aqaHrYWSWpBkr3A3tXY11Bhn+T19IL+\nyao62TXPJ9lcVZeSbAEud+0XgR19m2/v2l6lqo4tu2pJakDXCZ5emE/y2HL3NcxonAAfBmaq6kN9\ni04Bh7vpw8DJvvZDSTYk2QncAzy33AIlSSs3zGicnwD+D/DXXDsdc5RegJ8AvgeYBe6vqq932zwK\nvBe4Su+0zycW7dPROHoNR+NYw/WNQx23/micgWG/Fgx7XY9hbw3XNw513Pph7x20ktQAw16SGmDY\nS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUgKG/9VK3twHfWirpFmfYq8+o837kd6NLty1P\n40hSAwx7SWqAp3EkaQi3+nUtw37EbvX/QFI7xuFXdfnXtQz7sXBr/yeSNP48Zy9JDTDsJakBwzxw\n/CNJ5pO80Ne2KclUknNJTifZ2LfsaJLzSc4m2bdWhUuShjdMz/6jwH2L2o4AU1W1C3i2myfJbuAB\nYHe3zRNJ/PQgSSM2MIir6s+Ary1q3g9MdtOTwMFu+gBwvKquVNUscAHYszqlSpKWa7m97omqmu+m\n54GJbnorMNe33hywbZmvIUlaJSs+xVJVxdJjB8dhXKEkNW254+znk2yuqktJtgCXu/aLwI6+9bZ3\nba+R5Fjf7HRVTS+zFkm6TU13PyuXXsd8wErJ3cDTVfUD3fzjwFeq6oNJjgAbq+pId4H2KXrn6bcB\nzwDfV4teJElVlXfxsHAH7Th8+Amjr2McaoDxqMMarhmHOsahBoCw3Owc2LNPchz4KeC7k7wM/Drw\nm8CJJA8Cs8D9AFU1k+QEMANcBR5aHPSSpPU3VM9+1V/Unv2/sGc/bjXAeNRhDdeMQx3jUAOspGfv\nGHhJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCw\nl6QGGPaS1ADDXpIasNzHEt4Wet8lL0m3v6bDvmfUee8zXCStPU/jSFIDDHtJasCahH2S+5KcTXI+\nySNr8RqSpOGtetgnuQP4b8B9wG7gZ5O8dbVfR5I0vLXo2e8BLlTVbFVdAf4IOLAGryNJGtJahP02\n4OW++bmuTZI0Imsx9HKosYxJnl6D174Zz4z49SVp3axF2F8EdvTN76DXu1/s3Wvw2jeje/1xGOc+\nDjXAeNQxDjXAeNRhDdeMQx3jUMPypWp1bypKcifwN8BPA18AngN+tqpeWtUXkiQNbdV79lV1Nckv\nAZ8A7gA+bNBL0mites9ekjR+1v0O2lZvuEqyI8mnkryY5PNJ3te1b0oyleRcktNJNo661vWS5I4k\nZxYu1rd6LJJsTPKxJC8lmUnyww0fi6Pd78gLSZ5K8h2tHIskH0kyn+SFvrYbvvfuWJ3v8nTfoP2v\na9g3fsPVFeBXqur7gR8BfrF770eAqaraBTzbzbfiYWCGayO4Wj0Wvwt8vKreCvwgcJYGj0WSu4Ff\nAN5eVT9A7zTwIdo5Fh+ll439rvvek+wGHqCXo/cBTyRZMs/Xu2ff7A1XVXWpqp7vpr8NvETv/oP9\nwGS32iRwcDQVrq8k24F3Ab/PtWEOzR2LJG8GfrKqPgK9a15V9Q0aPBbAN+l1iu7qBnrcRW+QRxPH\noqr+DPjaouYbvfcDwPGqulJVs8AFevl6Q+sd9t5wxb/0YN4GfBqYqKr5btE8MDGistbb7wAfAF7p\na2vxWOwEvpTko0k+l+T3kryRBo9FVX0V+C3g7+iF/NeraooGj0WfG733rbx6SPvALF3vsG/+anCS\nNwF/DDxcVd/qX1a9q+W3/TFK8m7gclWd4QaDl1s5FvRGxL0deKKq3g78PYtOU7RyLJJ8L/B+4G56\nYfamJD/Xv04rx+J6hnjvSx6X9Q77YW+4ui0leT29oH+yqk52zfNJNnfLtwCXR1XfOvoxYH+S/wcc\nB/5Dkidp81jMAXNV9Zlu/mP0wv9Sg8fiHcBfVNVXquoq8CfAj9LmsVhwo9+JxVm6vWu7ofUO+88C\n9yS5O8kGehcYTq1zDSORJMCHgZmq+lDfolPA4W76MHBy8ba3m6p6tKp2VNVOehfgPllVP0+bx+IS\n8HKSXV3TvcCLwNM0dizoXZj+kSRv6H5f7qV3Ab/FY7HgRr8Tp4BDSTYk2QncQ+8G1hurqnX9AX6G\n3h22F4Cj6/36o/oBfoLe+enngTPdz33AJnrf03MOOA1sHHWt63xcfgo41U03eSyAHwI+A/wVvd7s\nmxs+Fr9K74/dC/QuSL6+lWNB71PuF4B/pndt8z1LvXfg0S5HzwL/adD+valKkhrgYwklqQGGvSQ1\nwLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDfj/F1Fc2gPCGKcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f732d01f6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "age_idx = feature_names.index('Age')  # Get the index of the 'Age' column.\n",
    "ages = X[:, age_idx]  # Extract the 'Age' column.\n",
    "\n",
    "n, bins, patches = plt.hist(ages, bins=10, range=(0,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As would be expected, the histogram peaks at an older age (75).\n",
    "\n",
    "___\n",
    "**Exercise:** Can you plot the histogram of another feature? Hint: if you remove the `bins` and `range` keyword arguments to `plt.hist`, it automatically finds a reasonable set of bins for your data.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model\n",
    "\n",
    "`Scikit-learn` uses a common API for all of their machine learning models, which makes it really easy to try different models. Let's start with a simple [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "**NOTE** A logistic regression model is *not* used for regression -- it is used for *classification*. Confusing! It's naming comes from the fact that it uses a linear model (similar to linear regression) to map the inputs to outputs. However, it then passes the output through a function (the logit function) which caps the value from 0 to 1, and increases the steepness of the curve around the midpoint - the image below plots the logit function. This allows the model to be used for classification.\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg\" width=\"30%\" height=\"30%\"></img>\n",
    "\n",
    "First, we'll split the dataset into a train and test set, with 80% used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# in training set: 2560\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = int(0.8 * len(X))\n",
    "print '# in training set:', num_train\n",
    "X_train = X[:TRAIN_SIZE]\n",
    "y_train = y[:TRAIN_SIZE]\n",
    "X_test = X[TRAIN_SIZE:]\n",
    "y_test = y[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because logistic regression is based on a linear model, it won't handle missing values represented by -1 very well. Scikit-learn has an `Imputer` class that provides basic strategies for filling in, or *imputing*, missing values. Let's use the strategy of using the mean of the known values to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values=-1, strategy='mean')\n",
    "X_train_imputed = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are also sensitive to different ranges for input features. For example, if one input features has a range of -1 to 1 and another has a range of 0 to 100, the feature with the larger range will disproportionately influence the model. (TODO: verify?) To combat this, we scale all the features to **zero mean and unit variance**, using scikit-learn's `StandardScaler` class.\n",
    "\n",
    "Note: We filled in missing values before scaling, otherwise the number used to represent missing values would distort the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we're ready to train the model. Scikit-learn's models all have a `fit()` function to fit the model to the training data and a `predict()` function to predict the outcome on new input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "Now that we have a model, how do we tell how good it is? Since we have labelled outcomes to compare predictions to, we can quantitatively measure how well the model is doing. This is where we use the test set. Because we only used the training set to develop the model, we can use the test set to see how well the model works on unseen data. With classification, each outcome is either predicted correctly or not, so the measure of success is binary.\n",
    "\n",
    "Models in scikit-learn usually have a `score()` method, which takes in a set of features and their labels. For logistic regression, this method returns the **accuracy** of the model on the input data. Accuracy is the number of outcomes correctly predicted divided by the total number of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85624999999999996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(imp.transform(X_test))\n",
    "model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from before that the proportion of positive outcomes is fairly low. This means that accuracy is not necessarily a very useful metric of model performance. A model which predicts survival for each patient (a negative outcome) would still be ~86% accurate! Thankfully, there are other metrics for model performance. Before we go into these metrics, let's define a few terms. In binary classification, there is a **positive** outcome and a **negative** outcome. Typically, the positive outcome is the case you'd like to detect (ex. detecting a malignant tumor, or detecting spam), and the negative outcome is the more normal, generally expected outcome (ex. not a tumor, or is email). In our example, the positive outcome is an in-hospital death. The prediction results can be one of the following:\n",
    "* **true positive**: a correctly predicted positive outcome\n",
    "* ** false positive**: a negative outcome incorrectly predicted as positive\n",
    "* ** true negative**: a correctly predicted negative outcome\n",
    "* ** false negative**: a positive outcome incorrectly predicted as negative\n",
    "\n",
    "Let's now apply these terms to other metrics for model performance:\n",
    "* **recall**, also known as **sensitivity**: of the patients who died, how many did we predict correctly. This is the number of true positives over the total number of positives.\n",
    "* **precision**, also known as **positive predictivity**: of the patients we predicted positive, what fraction was correct. This is the number of true positives over the total number we predicted as positive.\n",
    "\n",
    "One method of visualizing these metrics is to plot the precision-recall curve. As precision goes down, recall tends to go up. For example, we can achieve 100% recall if we predict everyone as positive, but this means our precision is 14.5% (the proportion of true positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlIySvwiIiXz/wFcMBfldPzqIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f735ab744d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted_probs = model.predict_proba(X_test_scaled)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predicted_probs[:,1])\n",
    "plt.plot(precision, recall, 's-', lw=1)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One measure of model performance (and the method used in the Physionet challenge) is the minimum of precision and recall. One would pick the point in the curve that maximizes this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max min of P/Se 0.505376344086\n"
     ]
    }
   ],
   "source": [
    "both = zip(precision, recall)\n",
    "print 'Max min of P/Se', max([min(r) for r in both])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly used metric in classification is the **Receiver Operating Characteristic (ROC) curve**. This curve plots the recall/sensitivity (also known as **True Positive Rate**) vs. the false positive rate:\n",
    "* **false positive rate**: number of false positives over the total number of negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.821792684862\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+UXWV97/H3d4YkkwFC1MGg+eHJQCTFKr8JFS2DUg2o\nYMGEInqb2nVl6UVdV1ttba/EWrVcqRcoXRQJEG9rCSB4iRZBrzqYCxgIEIgQWKQw5pcGEgigMGHC\nfO8fzz7MmTP7nNmTOXufc/b+vNaadc7e+5l9vjs/vvPMs5/9fczdERGR4uhodgAiIpItJX4RkYJR\n4hcRKRglfhGRglHiFxEpGCV+EZGC2a/ZASRhZppzKiKyD9zdqve1ReKH+OCTMLPl7r68weG0NF1z\nMeiai2Ey11yr06yhHhGRglHiFxEpmCIk/v5mB9AE/c0OoAn6mx1AE/Q3O4Am6G92AE3Q3+gTWpq1\neszsGuB9wFPu/tYabS4DTgNeBJa5+wMxbXxfx/hFRIqqVu5Mu8d/LbC41kEzOx04zN0XAB8Hrkg5\nHhGRwkt1Vo+7rzGzUp0mZwDfjtquNbOZZjbL3XekGZeISFbMjt0E+82Hrg4YrDraRfw+gNdX7Bse\nhr1Pw7bb3Nctm2xMzZ7OORvYUrG9FZgDKPGLSE709sD+HVACBqqO1doHsLxyZwcwC5aWaIBmJ36A\n6vEnPawlIm3F7LiV0HkOWFdIYZU9+TnNC6yGZif+bcDciu050b4xzGx5xWa/u/enF5aIyET0lqC7\na2S7xEhPvnooJz1m1gf0jdeu2Yl/NXABsMrMTgR21xrfL9rTeiJSX/1edllW+2YA3cmDT0nUIe4v\nb5vZhXHtUk38ZnYdcDLQY2ZbgAuBKVGAV7r7rWZ2upltAn4H/Fma8YhIntTrZWe979EaMbamtGf1\nnJugzQVpxiAi+2ZkNkp52ncze9St28se33ZgiPAD46WqY08y9tqejF4frtj36qyegUZE1OyhHhFp\nWeXZKGUlmtejjtvXLr3sd1E1Qyey9A73G/qyjSVQ4hcRmbSdwMvRlzO6J/8ko3vvAHsGYftAZuFV\nUeIXKZCxN0Sh9lBKT6axtbc5wMqY/Uuec79xZsbBjEuJX6RQqm+IQvsOpdTrZZdluW9J1f7hIRjY\nWecCmkaJXyRHRvfopzE2SR1Ce9wQTaK9etmtRIlfJFcqe/QlxvbkJ6I8G8VpjR513L726WW3EiV+\nkTaRrNjX62lcj771ZqNIYyjxi7SNJMW+sisPIO1LiV9kErItG9CIYl+7gWcYuSEKzXqISJpHiV9k\nUrIsG9CI3vxRaPhGlPhFKoRx9APmwZ4poyuEt0vZgMopjrV68q31MJFkT4lfZJTeHnjLlPYtG6Ap\njjI+JX6RtpG02NeYKY7DmuIolZT4pXDqP+TUeqsljdD0SmkMJX4poHoPOU30BmqWZQM0Pi+NocQv\nLWekRz59GrxUtSZzI6ZGNvIhJ42pS/tR4pcWVO6Rl0hnamS9Xv12Qi/+t4ye1aOyAZIfSvzSUsJ0\nytmHNm+KpMbRJf+U+KXF9PZAZ7ODEMk1JX5pCSPj+nO7xm08afUectINVMk/JX5pEeVx/SyKjOmG\nrBSbufv4rZrMzNzdbfyW0upql0Q4BHgNIfGXe+SdhAeVkpROmOi+eVXHhodh4En3+w6byPWItLJa\nuVM9fslYrZIIldQjF0mTEr+0mHJZgqVV+19BUyRFGkOJXzIThnnmH1S/Vb3plPf1NT4qkeJR4pcM\n1ZuqWV4g5FeM7u07mlUj0lhK/JKK+PVh51A78ddbIGR1XwohihSWEr+kJG592EHql0TQ/HmRLCjx\nS8OFh7FKM+KPqiSCSLMp8UsKekvQoecuRFqUEr+kYM9CmB6zvzzM8ydV+18c1pCOSHaU+CUFU2vU\n26k5zLPGfd2y9OIRkUqpJn4zWwxcQpjKscLdL6o63gP8G+F5/f2Ai919ZZoxSeOMXsLQGSmJMAfY\nwdj1YXUDV6QVpFarx8w6gceAU4FtwL3Aue6+saLNcmCau/919EPgMWCWu++tOpdq9bQgs6X90H3y\nyJ4SIdG/CByBbuKKNFczavWcAGxy94EogFXAmcDGija/Bt4WvZ8B7KpO+tKOngbWA8uq9u8Gtg5k\nHY2IjJZm4p8NbKnY3gosqmpzFfBTM9sOHMjYAi3S0gYXxa+UNQtYFbN/ySsayxdpvjQTf5IxpC8C\n6929z8wOBX5sZke6+wvVDaNhobJ+d+9vTJiy76ZNid+/k/hhnqeGUwxGpPDMrA/oG69dmol/GzC3\nYnsuoddf6e3AVwHc/T/N7EngcGBd9cncfXk6YcpEhZu63YthVo36C3OIT/wPv5heVCISdYj7y9tm\ndmFcuzQT/zpggZmVCBO4zwHOrWrzKOHm751mNouQ9J9IMSZpiN4SHDEL7iDM3nmZ8Ate5TKGS6q+\nZ3hYZZVFWkNqid/d95rZBcDthOmcV7v7RjM7Pzp+JfA14FozexDoAD7v7s+kFZM0ymB0r6beWP6N\nekZEpEWl+p/T3X8I/LBq35UV73cCH0gzBklDrbF9EWkH6pXJuMY+qFW+dbOdsVM2ATYPZRWbiEyc\nEr8k0FuC7ooyDOV7tDVLMKxNPSQR2WdK/BJrdC9/FqPn65cf0Potowuu7QWGdsC2gcwCFZEJU+KX\nGqp7+ZXq3dS95ZAUgxKRBlDil32gsX2RdqbELzXsWRhfjgE0ti/S3pT4pYbKmvq7gWcY/aCWyiuL\ntCsl/oIzO3YT7Def8AAdo2vqlx2FSiyL5IcSf+H19sD+HSPbJUJN/V8RZu+8jHr4IvmixF8g8b37\nnhqtVY5BJK/0H7hQ4nr3jzYrGBFpEiX+gggPZJVmJP8O1dQXySsl/sLoLUHHBNYtVk19kbxKnPjN\nrNvd9Z8+d7YDQ4RpmqqpL1IE4yZ+M3s7sIKwJu5cMzsK+Li7fzLt4KSR9iyE6TH7az6MpamaIjmV\npMd/CbAYuAXA3deb2cmpRiUpmNoV37uH0VM1h4dh79MqtCaSX4mGetx9s9mo4eG96YQjaQjTOOcf\npN69iECyxL/ZzE4CMLOpwKeBjalGJQ3W2wPPEkopL6s6ttth60DmIYlI05i7129gdjBwKWFRdAN+\nBHza3XelH96rMbi7T2BGioyupz+bcItmZUzLJc+53zgz0+BEJBO1cmeSHv+b3f3DVSc7CbizUcFJ\nGirr6Q/WbSkixZIk8V8OHJ1gn7SI0Nt/4ztHl1XeTfz4/g79VBApmJqJ38z+AHg7cLCZfZYwzANh\nzKCj1vdJK+gtQUfV31GtCpuPqGaDSMHU6/FPJST5zui17HngQ2kGJfsuzOCZ2xsKsJVtJ5Rg+JOq\n1i8Oq8KmSPEkublbcveBbMKpGYNu7iZktmQ37H9QGNcvJ/8SmsYpUjyTubn7opldDBzByKOf7u7v\namSA0mg7CbX0VU9fREZLkvi/A1wPvB84nzAR/OkUY5IY4YZt92LYczCj7rGUV8wqm1PxujLmTJq+\nKVJ0SRL/69x9hZl92t3vAO4ws3VpBybVektwxKywOlalEqP3DTKyRm71mP5ehydVZE2k4JIk/pej\n19+Y2fsJdwpfk15IEm9wUfK2NdfI/bn7fX2NiUdE2lWSxP9VM5sJfA74J2AG8N9TjUpiTJuSrJ1m\n8IhIfeMmfnf/fvR2N9AHYGYnpBiTVAlTNHs7k7WuWYhtjfu6ZY2LSkTaVb0HuDqAPwYOBX7p7rea\n2XHA14DXE8YTJBO9PSPPz4mITE7NefxmtgKYD9wDnAz8GlgI/A1wi4/3AEAjgyzIPP7RhdWmMTJb\nZw7hZu1BwA5G6unD2Fk9XYSfy5X2DML269XjFymWfZnHfyLwNncfNrMu4DfAoROpymlmiwkLuXQC\nK9z9opg2fcD/AqYAO929L+n586eysFqJkdk6g8AsYFXM9yx5xf1GrZ0sIonVSxhD7j4M4O6DZvbk\nBJN+J6GY26nANuBeM1vt7hsr2swE/hl4r7tvNbOefbqK3BhcNLqwWqXtjK2lD7B5KL14RCSP6iX+\nhWa2oWL70Iptd/e3jXPuE4BN5XIPZrYKOJPRi7h8GLjJ3bdGJy34HPN6M3dq3rRdm1IwIpJT9RL/\n703y3LOBLRXbW4HquegLgClm9jNCIbhL3f1fJ/m5OaQpmiLSODUTfwMKsyW5+TsFOAZ4N2GM424z\n+4W7P17d0MyWV2z2u3v/JONrKeHG7vwaUzY1RVNExhfdM+0br12aNwW3AXMrtucSev2VthBu6L4E\nvGRmPweOBMYkfndfnlKcLaK3FEog7WCksFp5to6KrInI+KIOcX9528wujGuXZuJfBywwsxJhrOIc\n4NyqNrcAl0c3gqcRhoK+mWJMTTd6ymbllMwZaOaOiGQhUTIxs25grrs/lvTE7r7XzC4AbidM57za\n3Tea2fnR8Svd/VEzuw14CBgGrnL3RyZ8FW2lcspmWQl4FM3cEZEsJFmI5QzgG8A0dy+Z2dHAl939\njCwCjGLIxQNcI6tjzay6lhIh8S9EC6aISKPUyp1J1s5dThiCeRbA3R8AehsaXWH09oxN+iIi2Uoy\n1DPk7rvNRuWr4ZTiyZ3RY/qz67TcCaxn7FDPboetAymFJyIFlCTxP2xm5wH7mdkC4NPAXemGlSeV\nY/qDddrVXDHreU3ZFJFGSjLGvz+hMNt7ol23A19x93pZrKHaZYx/7Iyd8myd10UtBqOvZwhTNqsL\nrc2rOuPwEAxsdr/vsNSDF5HcqZU7kyT+Y9z9/tQiS6B9Ev/Sfug+eWRPiXDTtjyJZxDdwBWRrOxL\ndc6yb5rZIcCNwPXu/suGR1cYKr0gIs03bo8fwMzeACyNvmYAN7j7V1KOrfLzW7bHH6Zo7jcfujpG\nD+vA2B5/CfX2RSQrk+nx4+6/Bi41s58CXwC+BGSW+Ftbbw/s3zGS5KvtJIznl8swqPSCiDTXuInf\nzI4g9PQ/BOwCrgc+m3JcbWS4VgH9SM3ZOs+53zgzhYBEROpK0uO/hlBA5r3uvi3leNpQR8VDcJW9\ne2ek0NqSqu8ZHoKBgq89ICLNMm7id/cTswikHYXx/d6KUsrq3YtI66uZ+M3sRndfUrUKV1mSFbgK\noLcHWvKes4hITfV6/J+JXt/P2OyWZJGVAhjuDlM0ISyM/hIa1hGRVldvBa5yRvuku3+h8piZXUSY\n3VNwHR1wOBreEZF2kuTJ3Qfc/eiqfRvc/a2pRjb681puHn+0VOKfwhBwVEyLn+5w//khGYclIvKq\nCc/jN7NPAJ8EDq0a5z8QuLPxIbab3lJ4PYr4h7IeiZvULyLSdPXG+P8d+CHwD4RhnfJPjRfcfVfa\ngbWHLYSCa2NKMKCHskSkVdUc6jGzGe7+vJm9jpibue7+TNrBVcTSMkM9YYinezHMnAWvReP7ItKq\n9qVkw3XA+4D7iJ/FM79BsbWZ3hIcMSuUZ9hN/DDPjsxKVouITFS9WT3vi15LmUXTFgYXjbzX+L6I\ntJ8ktXpOAh5099+a2UeBo4FL3f1XqUfXkqZNCa9aKlFE2lOS6ZwbgCOBtxIGtK8Glrj7yfW+r5Fa\nZYw/KtFwKLyF8MDWyphWGt8XkdZQK3d2xDWustfdh4EPAv/s7pcTpnQWkEo0iEj7S1Kd8wUz+yLw\nEeCdZtYJTEk3rFY13B2mb64HdhCqVZc5Ks8gIu0gSeI/B/gw8DF3/42ZzQO+kW5YraqjA2YRqlRX\nW/KK+01Ts45IRGSiki69eAhwPKFbe4+7P5V2YFWf3yJj/EuGYYdBb8zRjYPua6dnHpSISA37vPSi\nmS0l9PDviHZdbmZ/6e43NjjGdmDwLmqsm7s241hERPZJkqGevwWOL/fyzexg4CdAARP/5mF4tkMl\nGkSknSVJ/AY8XbG9iwJObQmlGkoG3405evaQ+7plGYckIrJPkiT+24DbzezfCQn/HELxtoLpLcEz\nFj/Mo4k8ItI+kt7cPQt4R7S5xt2/l2pUYz+/6Td3zc54CV7bpYe2RKRd7Es9/jcTbuoeBjwE/KW7\nb53ghy4GLgE6gRXuflGNdscDdwNL3f3miXxGdqZNUVE2EcmDekM91wDfBtYAHwAuA85KeuLoQa/L\ngVOBbcC9Zrba3TfGtLuIMKTUkvcOolINnSrKJiJ5UC/xH+DuV0XvHzWzByZ47hOATe4+AGBmq4Az\ngY1V7T5FuGN6/ATPnyGVahCR/KiX+LvM7JjovQHTo20D3N3vH+fcswlLVJVtBRZVNjCz2YQfBu9i\n5AGxlhLN5plRpxonqsYpIu2kXuL/DfCPdbZPGefcSZL4JcBfububmVGnW21myys2+929P8H5G6C3\nBB1Wv1SDpnKKSPOZWR/QN267JLN69jGAE4Hl7r442v5rYLjyBq+ZPcFIsu8hPAn1X919ddW5Mp/V\nE3r6nefAG7qgC9iOSjWISDvZ55INk7AOWGBmJULWPAc4t7KBu7+aSc3sWuD71Um/eXpL0N0V3g+i\nUg0ikhepJX5332tmFwC3E6ZzXu3uG83s/Oj4lWl9duNtJ4zxjynVMKxSDSLSblIb6mmk5gz1lB/Y\nAihRo7d/h/sNfZkFJSIyAZOpztkBnAfMd/e/i+rxH+Lu96QQZwspr627mxqzeYY0m0dE2lGSNXf/\nBRgG3uXuC83stcCP3P24LAKMYsi0xz+ytu7+qLcvIu1qMjd3F7n70eUHuNz9GTPL+dKLvT1hTH8H\n8CvGLrG4Z1Bj+yLSrpIk/pejsgrAq/X4h9MLqblCb3/+QfXn7a/W9E0RaVsdCdr8E/A94PVm9jXg\nTuDrqUbVVL096c5yFRFprnEznLv/m5ndB7w72nVmdaG1fBnuDrNPtzP2hi7A5qFs4xERaawks3rm\nAb8Dvh/tcjOb5+6bU42saTqi34L0wJaI5FOSMY1bGam70wXMBx4D3pJWUM0SyjTM79QDWyKSZ0mG\nen6/cjuq0PnfUouoqXpL4bVmb3+NCrKJSLub8F1Md7/fzBaN37JdbQGeIaa3j3r7IpIHScb4P1ex\n2QEcQ1hRKzdGV+I8nNrr6qq3LyLtL0mP/4CK93uBHwA3pRNOs1RW4tS6uiKSb3UTf/Tg1gx3/1y9\ndu0sPLA1+1DojvZoXV0Rybeaid/M9otKK59kUcGHLAPLTm9PmLcPKsgmIkVQr8d/D2E8fz1wi5nd\nSLjDCWHN3ZvTDi4b5Qe2oHZvf+ldGt8Xkbyol/jLFd26gF2EOY6VcpL4O5KUrRARyY16if9gM/ss\nsCGrYLIWlV/uDA9rvYwqcYpIEdRL/J3AgVkF0hy9PeEXmznUnsK5ema2MYmIpKte4v+Nu385s0ia\nZkv0urRq/yvAwM6MgxERSV3B6w8Pd9d/YOu+wzIOSEQkdfUS/6mZRdE0HR16YEtEiqZm4nf3XVkG\n0iQdemBLRIqm4EM9mx2eNRVkE5EisXZ4ILfWSvH7fr5jN8EB8+DgKfDdmBZnD7nfNLVRnyci0gy1\ncmdBH17q7YFTptT+hUcPdYlIfhVuqCeUYC7NCFs7iR/ff2o4u4hERLJVuMQfSjB3RL/6zCE+8T/8\nYsxOEZFcKFTiD739N75zpASzpnKKSPEUKvFHvf2K8XtN5RSR4ilY4i/bThjff4XRpRpeAfbugG0D\nzYhKRCQLBUv8exbCdEKF6eUxx5fe4X5TX6YhiYhkrGCJf2pX6OnHrrLlWmVLRIog9cRvZouBSwhl\nnle4+0VVx88DPk+oj/wC8Al3f6jxcRy3Et50UJ0SzM9rlS0RKYJUE3+0WPvlhIJv24B7zWy1u2+s\naPYE8Ifu/lz0Q+JbwImNj6a3BE8TvqpLNOwFnlQJZhEphLR7/CcAm9x9AMDMVgFnAq8mfne/u6L9\nWkKXPAWDi2AWsCrm2JJXVIJZRIoi7dIEsxlZ6QRga7Svlj8Hbk0nlGlT0jmviEh7SbvHn7gCnJmd\nAnwMOKnG8eUVm/3u3p/83MethPmdKtEgInlmZn1A33jt0k7824C5FdtzCb3+UczsbcBVwGJ3fzbu\nRO6+fN/D6C2FV5VoEJH8ijrE/eVtM7swrl3aiX8dsMDMSoSnps4Bzq1sYGbzgJuBj7j7pnTC2LMQ\nnic8oKUbuyJSbKkmfnffa2YXALcTpnNe7e4bzez86PiVwJeA1wBXmBnAkLuf0NhIpnbpxq6ISFCI\nhVjMluyGHQdBb8zRjYPua6dPIjwRkZZUK3cW5Mnd4e46ZRrWZhyMiEhTFSTxq0yDiEhZQRJ/D3BT\nzP6z96pMg4gUTUESf635+5rMIyLFU5DE30N84t+QcRwiIs2XdsmGFtFR4zpr7RcRya9c9/hDqYbu\nxWCdNUo1KPGLSOHkOvGHUg1HzIJHqFGqYZ+fDRARaVc5T/x7FobXp4lP/E+3/tNrIiINlvPEP7Ur\nvM4iPvEvUVVOESmcnCf+MpVjFhEpy3niH+4OryrHLCJSlvPEXy7VsANYWrHfgeEhGNATXCJSODlP\n/D2dNUo1DLvfNDXzcEREWkDOE/8uix/i2aVpnCJSWDlP/AdTYzZPxnGIiLSOvD+5Wqtnrx6/iBRW\nbnv8oVzD/tR4cCvbYEREWkhuE38o1wAa6hERGS3HiX/PQniKsatuAWzWg1siUlg5TvxTu+BwYGXM\nsSUvZByMiEjLyHHiB9hN/FDPjsGMAxERaRk5TvzD3XAU8Yn/kUczDkZEpGXkOPGXyzUsq9q/22Hr\nQObhiIi0iBwn/prlGtx93bKsoxERaRU5Tvwq1yAiEifHiV/lGkRE4uS5ZIPKNYiIxMhxj7/mOrsZ\nxyEi0lpynPg11CMiEifHiX+zw7KYYZ3Nnn0sIiKtI9XEb2aLgUuATmCFu18U0+Yy4DTgRWCZuz/Q\nmE+fNwwrO8fuX6I6PSJSaKklfjPrBC4HTgW2Afea2Wp331jR5nTgMHdfYGaLgCuAExsTwVPDsDwm\n8T+lxC8ihZZmj/8EYJO7DwCY2SrgTGBjRZszgG8DuPtaM5tpZrPcfcdkPjjU4p/fET/G//CLkzm3\niEi7SzPxzwa2VGxvBRYlaDMHmFTiD7X4X+5UgTYRkbHSTPxJb6JW34Bt0M1XFWgTEYmTZuLfBsyt\n2J5L6NHXazMn2jeGmS2v2Ox39/7xQ1hetf3wc/DkwPjfJyLSfsysD+gbt517OrMbzWw/4DHg3cB2\n4B7g3Jibuxe4++lmdiJwibuPublrZu7uiZ+4NVvaDzecPPbI0jvcb+ib4KWIiLSlWrkztR6/u+81\nswuA2wnTOa92941mdn50/Ep3v9XMTjezTcDvgD9LKx4REQlS6/E30sR7/MetHFlsvdITAyrJLCJF\nUSt35jLxi4hI7dyZ5+qcIiISI/eJP7rLXSi65mLQNRdDGtec+8RPgqlNOdTX7ACaoK/ZATRBX7MD\naIK+ZgfQBH2NPmEREr+IiFRQ4hcRKZi2mdXT7BhERNpR207nFBGRxtFQj4hIwSjxi4gUTG4Sv5kt\nNrNHzexxM/tCjTaXRccfNLOjs46x0ca7ZjM7L7rWh8zsTjN7WzPibKQkf89Ru+PNbK+ZnZVlfI2W\n8N91n5k9YGa/NLP+jENsuAT/rnvM7DYzWx9d87ImhNkwZnaNme0wsw112jQ2d7l7238RisBtAkrA\nFGA98HtVbU4Hbo3eLwJ+0ey4M7jmPwAOit4vLsI1V7T7KfAD4Oxmx53y3/FM4GFgTrTd0+y4M7jm\n5cDXy9cL7AL2a3bsk7jmdwJHAxtqHG947spLj//VZR7dfQgoL/NYadQyj8BMM5uVbZgNNe41u/vd\n7v5ctLmWsN5BO0vy9wzwKeC7wNNZBpeCJNf7YeAmd98K4O47M46x0ZJc86+BGdH7GcAud9+bYYwN\n5e5rgGfrNGl47spL4o9bwnF2gjbtnAiTXHOlPwduTTWi9I17zWY2m5Aoroh2tfO0tSR/xwuA15rZ\nz8xsnZl9NLPo0pHkmq8C3mJm24EHgc9kFFuzNDx3pbkCV5aavMxjUySO3cxOAT4GnJReOJlIcs2X\nAH/l7m5mxti/83aS5HqnAMcQFjzqBu42s1+4++OpRpaeJNf8RWC9u/eZ2aHAj83sSHd/IeXYmqmh\nuSsvib+hyzy2iSTXTHRD9ypgsbvX+3WyHSS55mOBVSHn0wOcZmZD7r46mxAbKsn1bgF2uvtLwEtm\n9nPgSKBdE3+Sa3478FUAd/9PM3sSOBxYl0mE2Wt47srLUM86YIGZlcxsKnAOUP0ffTXwXwCiZR53\nu/uObMNsqHGv2czmATcDH3H3TU2IsdHGvWZ373X3+e4+nzDO/4k2TfqQ7N/1LcA7zKzTzLoJN/8e\nyTjORkpyzY8CpwJEY92HA09kGmW2Gp67ctHj9wIu85jkmoEvAa8Broh6wEPufkKzYp6shNecGwn/\nXT9qZrcBDwHDwFXu3raJP+Hf8deAa83sQULn9fPu/kzTgp4kM7sOOBnoMbMtwIWEIbzUcpdKNoiI\nFExehnpERCQhJX4RkYJR4hcRKRglfhGRglHiFxEpGCV+EZGCUeKXlmFmr0Tlhctf8+q0/W0DPm+l\nmT0RfdZ90cMxEz3HVWa2MHr/xapjd042xug85T+Xh8zsZjM7YJz2R5rZaY34bMknzeOXlmFmL7j7\ngY1uW+cc1wLfd/ebzeyPgIvd/chJnG/SMY13XjNbSSjf+4912i8DjnX3TzU6FskH9filZZnZ/mb2\nf6Pe+ENmdkZMmzeY2c+jHvEGM3tHtP89ZnZX9L03mNn+tT4mel0DHBZ972ejc20ws89UxPIf0eIf\nG8xsSbS/38yONbN/AKZHcfxrdOy30esqMzu9IuaVZnaWmXWY2TfM7J5ogY2PJ/hjuRs4NDrPCdE1\n3m9hoZ03R2UO/g44J4plSRT7NWa2Nmo75s9RCqbZixDoS1/lL2Av8ED0dRPhkf0Do2M9wOMVbV+I\nXj8HfDF63wEcELW9A5ge7f8C8D9iPu9aooVagCWEpHoMofzBdGB/4JfAUcDZwLcqvndG9Poz4JjK\nmGJi/CCwMno/FdgMTAM+DvxNtH8acC9QiomzfJ7O6M/lk9H2gUBn9P5U4LvR+z8FLqv4/q8B50Xv\nZwKPAd1rVc5JAAACfUlEQVTN/vvWV/O+clGrR3LjJXd/dVk5M5sCfN3M3kmoQ/NGM3u9uz9V8T33\nANdEbf+Puz9oZn3AEcBdUY2iqcBdMZ9nwDfM7G+BpwhrFvwRcLOHapeY2c2EFZJuAy6OevY/cPf/\nN4Hrug24NOqNnwbc4e57zOw9wFvN7ENRuxmE3zoGqr5/upk9QKjLPgD8S7R/JvC/zewwQpne8v/n\n6nLU7wE+YGZ/EW1PI1R7fGwC1yA5osQvrew8Qu/9GHd/xUL53a7KBu6+JvrB8H5gpZl9k7Ca0Y/d\n/cPjnN+Bv3D3m8s7zOxURidNCx/jj1tY6/R9wN+b2U/c/StJLsLdBy2shfteYClwXcXhC9z9x+Oc\n4iV3P9rMphOKl50JfA/4CvATd/9jM3sT0F/nHGd5+9bolwbTGL+0shnAU1HSPwV4U3WDaObP0+6+\nAlhBWLv0F8BJFhbpKI/PL6jxGdULXKwBPmhm06P7Ah8E1pjZG4BBd/8OcHH0OdWGzKxWZ+p6wmI4\n5d8eICTxT5a/Jxqj767x/US/hXwa+KqFX2VmANujw5UVG58nDAOV3R59H9HnTH6xbmlrSvzSSqqn\nmH0HOM7MHgI+CmyMaXsKsN7M7if0pi/1sO7sMuC6qHTvXYSa7eN+prs/AKwkDCH9glDm+EHgrcDa\naMjlS8Dfx5zrW8BD5Zu7Vef+EfCHhN9EyuvDriDUzr/fzDYQlouM+8Hx6nncfT1hMfKlwP8kDIXd\nTxj/L7f7GXBE+eYu4TeDKdEN8l8CX67xZyEFoemcIiIFox6/iEjBKPGLiBSMEr+ISMEo8YuIFIwS\nv4hIwSjxi4gUjBK/iEjBKPGLiBTM/weHegDRluPKRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73225f3750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "print 'AUC', roc_auc_score(y_test, predicted_probs[:,1])\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predicted_probs[:,1])\n",
    "plt.plot(fpr, tpr, 's-', lw=1)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect predictor would have a true positive rate of 1 while the false positive rate is 0. In general, we want to maximize the area under the ROC curve. The greater the area, the better performing the model is. `sklearn` has a function [`roc_auc_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) that computes the area under the curve (AUC).\n",
    "___\n",
    "**Exercise:** If I can only tolerate a false positive rate of 20% (maybe I have limited hospital resources), what is the maximum recall I can achieve with the logistic regression model?\n",
    "___\n",
    "**Exercise:** Try using a [Random Forest Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) instead of a logistic regression model. A random forest model averages the result of many decision trees trained on random subsets of the data. How do the results compare? What if you increase the number of estimators (the number of trees in the forest)? \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "The logistic regression model takes in a hyperparameter *C* that controls the regularization. Regularization is the method of introducing constraints to a solution to prevent overfitting. In logistic regression, the type of regularization used is usually a penalty on very large coefficients. *C* controls the amount of penalty incurred. So how do we pick the best *C* for our dataset? For that matter, how do we know logistic regression is even the model we should use?\n",
    "\n",
    "Well, we can try all of the various possibilities and evaluate the solution on a test set. The model that gives the best results is the winner. However, we don't want to use our test set for this selection process because we then won't have any unseen data to make a final evaluation. We need a *third* partition to our dataset set to evaluate the model, referred to as the \"validation set\". Instead of creating a fixed third partition as the validation set, we usually choose to use the method of **cross-validation.** This uses different splits of the training set for train and evaluation.\n",
    "\n",
    "Scikit-learn has a library of utilities for cross-validation and performance evaluation in the `sklearn.cross-validation` module. It has several classes which automatically generate different splits of the training set. We will be using the `StratifiedKFold` iterator, which splits the data into *n* folds. *n - 1* folds are used for training, and the *nth* fold is used for test. A stratified K-fold maintains approximately the same percentage of each outcome class in each fold as in the complete set.\n",
    "\n",
    "Let's use the stratified K-fold method to create train/test splits and use the average of the results of the K folds to evaluate our model choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max min of P/Se 0.34328358209\n",
      "Max min of P/Se 0.34693877551\n",
      "Max min of P/Se 0.404255319149\n",
      "Max min of P/Se 0.510638297872\n",
      "Max min of P/Se 0.382978723404\n",
      "Max min of P/Se 0.425531914894\n",
      "Max min of P/Se 0.521739130435\n",
      "Max min of P/Se 0.45652173913\n",
      "Max min of P/Se 0.509803921569\n",
      "Max min of P/Se 0.458333333333\n",
      "Mean value over 10 folds: 0.436002473739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "skf = StratifiedKFold(y, 10)  # 10 = number of folds\n",
    "\n",
    "max_P_Se_values = []\n",
    "for train, test in skf:\n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    X_test = X[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    imp = Imputer(missing_values=-1, strategy='mean')\n",
    "    X_train_imputed = imp.fit_transform(X_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    X_test_scaled = scaler.transform(imp.transform(X_test))\n",
    "    predicted_probs = model.predict_proba(X_test_scaled)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, predicted_probs[:,1])\n",
    "    both = zip(precision, recall)\n",
    "    max_P_Se = max([min(r) for r in both])\n",
    "    print 'Max min of P/Se', max([min(r) for r in both])\n",
    "    max_P_Se_values.append(max_P_Se)\n",
    "\n",
    "print 'Mean value over 10 folds:', numpy.mean(max_P_Se_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Exercise:** Use Stratified K-fold to measure the performance of the random forest classifier.\n",
    "___\n",
    "**Exercise:** Use Stratified K-fold to measure the performance of logistic regression with C = 0.1. How about C = 0.01? (You can change C, which defaults to 1, by passing C as a parameter to the model: `linear_model.LogisticRegression(C=0.1)`.\n",
    "___\n",
    "\n",
    "\n",
    "We randomly tested a couple of values for C, but how do we actually find the best value of C? What if we had a *second* parameter *a*? Now the problem is even harder! The traditional method is [**grid search**](http://scikit-learn.org/stable/modules/grid_search.html), where you exhaustively try all the parameter combinations until the best model is found. More efficient methods have been developed over the years. Scikit-learn has several different implementations of parameter search algorithms in the [`sklearn.grid_search`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.grid_search) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Test Set\n",
    "\n",
    "So far, we haven't touched the test set. This was intentional, so that you have a pristine dataset to test your final model on after we went through all the topics above. Try loading the data on your own from [https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/test-a.csv](https://raw.githubusercontent.com/lydiagu/ml-tutorial/master/physionet/test-a.csv) and evaluating your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Raw data is not a nice csv. How did we preprocess the data?\n",
    "\n",
    "We only used the training set from the challenge website because that's the only labelled dataset available to the public. We further split the challenge training set into a train and test set for this tutorial (`train-a.csv` and `test-a.csv`).\n",
    "\n",
    "The featurization code can be found on [github](https://github.secureserver.net/lgu/techfest-ml-tutorial/blob/master/physionet/create_featurized_datasets.py). It both featurizes the dataset and splits it into train and test sets. Each patient record file is read and stored as a dictionary of metric name to list of measurements. Then for each metric name, we compute the min, max, mean, first value, last value and difference between first and last values. If no measurements were recorded for that metric, all of those features would be -1. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
