{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing data\n",
    "This part of the tutorial loads data about Boston housing and median house prices. The goal is to predict the housing price in each district given a series of features.\n",
    "\n",
    "Features include race, air quality and plot size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_boston' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-381754304d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboston\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_boston' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "boston = load_boston()\n",
    "X_train = boston[\"data\"][:100]\n",
    "y_train = boston[\"target\"][:100]\n",
    "X_test = boston[\"data\"][100:]\n",
    "y_test = boston[\"target\"][100:]\n",
    "\n",
    "all_features = boston[\"feature_names\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WE are using numpy sklearn for these examples\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ALLOW inline graphs\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "X_train = boston[\"data\"][:100]\n",
    "y_train = boston[\"target\"][:100]\n",
    "X_test = boston[\"data\"][100:]\n",
    "y_test = boston[\"target\"][100:]\n",
    "\n",
    "all_features = boston[\"feature_names\"]\n",
    "print str(all_features)\n",
    "print len(X_train)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit (X_train, y_train)\n",
    "rf = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Variance score: %.2f' % clf.score(X_test, y_test))\n",
    "print('Variance score: %.2f' % rf.score(X_test, y_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LET's plot it\n",
    "import matplotlib.pyplot as plt\n",
    "idx = list(all_features).index('LSTAT')\n",
    "plt.scatter([x[idx] for x in X_test], y_test,  color='black')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#housing.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "#crossvalidate the scores on a number of different random splits of the data\n",
    "for train_idx, test_idx in ShuffleSplit(len(X), 100, .3):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "    r = rf.fit(X_train, Y_train)\n",
    "    acc = r2_score(Y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test, rf.predict(X_t))\n",
    "        scores[names[i]].append((acc-shuff_acc)/acc)\n",
    "print \"Features sorted by their score:\"\n",
    "sorted_features = sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True)\n",
    "print sorted_features\n",
    "good_features = [x[1] for x in sorted_features]\n",
    "X_selected = []\n",
    "for line in X_train:\n",
    "    x_out = []\n",
    "    feature_num = 0\n",
    "    for feature_name in all_features:\n",
    "        if feature_name in good_features:\n",
    "            x_out.append(line[feature_num])\n",
    "        feature_num += 1\n",
    "    X_selected.append(x_out)\n",
    "print good_features\n",
    "\n",
    "# SCALE it\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit (X_selected, Y_train)\n",
    "\n",
    "print('Variance score: %.2f' % clf.score(X_selected, Y_train))\n",
    "\n",
    "\n",
    "# LET'S try scaling the data\n",
    "clf_scaled = linear_model.LinearRegression()\n",
    "clf_scaled.fit (X_train_scaled, Y_train)\n",
    "print('Variance score: %.2f' % clf_scaled.score(X_train_scaled, Y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
