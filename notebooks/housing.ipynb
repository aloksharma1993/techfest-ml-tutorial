{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing data\n",
    "This part of the tutorial loads data about Boston housing and median house prices. The goal is to predict the housing price in each district given a series of features.\n",
    "\n",
    "Features include race, air quality and plot size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import warnings\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "boston = load_boston()\n",
    "X_train = boston[\"data\"][:100]\n",
    "y_train = boston[\"target\"][:100]\n",
    "X_test = boston[\"data\"][100:]\n",
    "y_test = boston[\"target\"][100:]\n",
    "\n",
    "all_features = boston[\"feature_names\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's see some of the data. X is a matrix of all feature values. y is a vector of target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "y training size is 100\n",
      "X training size is 13 x 100\n"
     ]
    }
   ],
   "source": [
    "all_features = boston[\"feature_names\"]\n",
    "print str(all_features)\n",
    "print 'y training size is %d' % len(y_train)\n",
    "print 'X training size is %d x %d' % (len(X_train[0]), len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Let's try a couple of models. First a linear regression based on least squares. The variance should be close to 1 if the model is good. Don't be fooled by the R^2 on the training set. It's a line that does not describe the reality of taking on a real set of new random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 train is 0.880705 # bogus\n",
      "R^2 test is -12.723166\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "clf_linear_simple = linear_model.LinearRegression()\n",
    "\n",
    "clf_linear_simple.fit (X_train, y_train)\n",
    "linear_r2 = r2_score(y_train, clf_linear_simple.predict(X_train))\n",
    "print 'R^2 train is %f # bogus' % linear_r2\n",
    "linear_test_r2 = r2_score(y_test, clf_linear_simple.predict(X_test))\n",
    "print 'R^2 test is %f' % linear_test_r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "The random forest optimizes the results under the hood. This is the easy way. This is an overestimate of the R^2 again. This really is random. Try play twice and watch the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bdfd7c8b6a98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrf_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlinear_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'R^2 score: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrf_first\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_first = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "rf_first.fit(X_train, y_train)\n",
    "linear_r2 = r2_score(y_train, clf.predict(X_train))\n",
    "print('R^2 score: %.2f' % rf_first.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b1a853910df8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# fits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'Feature: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#idx = list(all_features).index('LSTAT')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_features' is not defined"
     ]
    }
   ],
   "source": [
    "# LET's plot it\n",
    "import matplotlib.pyplot as plt\n",
    "# ALLOW inline graphs\n",
    "%matplotlib inline\n",
    "\n",
    "# FOR THE student:\n",
    "# Look at more graphs of features and find those that look to be the best\n",
    "# fits\n",
    "\n",
    "for feature_name in all_features[:2]:\n",
    "    print 'Feature: %s' % feature_name\n",
    "    #idx = list(all_features).index('LSTAT')\n",
    "    idx = list(all_features).index(feature_name)\n",
    "    plt.scatter([x[idx] for x in X_test], y_test,  color='black')\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#housing.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Selection\n",
    "We try to find the best features using a series of random sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(2.1105, 'AGE'), (2.1087, 'INDUS'), (2.0948, 'CHAS'), (2.0822, 'CRIM'), (2.0819, 'B'), (2.0611, 'ZN'), (1.9517, 'PTRATIO'), (1.9371, 'TAX'), (1.9355, 'NOX'), (1.8634, 'RAD'), (1.8517, 'RM'), (1.7591, 'DIS'), (1.5898, 'LSTAT')]\n",
      "['AGE', 'INDUS', 'CHAS', 'CRIM', 'B', 'ZN', 'PTRATIO', 'TAX', 'NOX', 'RAD', 'RM', 'DIS', 'LSTAT']\n",
      "R^2 selected train linear score: 0.88\n",
      "R^2 selected test linear score: -12.72\n",
      "R^2 test scaled linear score: 0.50\n",
      "R^2 test select scaled linear score: 0.50\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = boston[\"data\"]\n",
    "Y = boston[\"target\"]\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "scores = defaultdict(list)\n",
    " \n",
    "#crossvalidate the scores on a number of different random splits of the data\n",
    "for train_idx, test_idx in ShuffleSplit(len(X), 100, .3):\n",
    "    X_train_shuf, X_test_shuf = X[train_idx], X[test_idx]\n",
    "    Y_train_shuf, Y_test_shuf = Y[train_idx], Y[test_idx]\n",
    "    r = clf.fit(X_train_shuf, Y_train_shuf)\n",
    "\n",
    "    acc = r2_score(Y_test, clf.predict(X_test_shuf))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test_shuf.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test_shuf, clf.predict(X_t))\n",
    "\n",
    "        scores[all_features[i]].append((acc-shuff_acc)/acc)\n",
    "\n",
    "print \"Features sorted by their score:\"\n",
    "sorted_features = sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True)\n",
    "print sorted_features\n",
    "good_features = [x[1] for x in sorted_features]\n",
    "\n",
    "# FOR the student:\n",
    "# Reduce this amount to remove features\n",
    "\n",
    "FEATURE_COUNT = 13\n",
    "\n",
    "print good_features[:FEATURE_COUNT]\n",
    "\n",
    "# USE good features to train next model\n",
    "X_selected_train = []\n",
    "for line in X_train:\n",
    "    x_out = []\n",
    "    feature_num = 0\n",
    "    for feature_name in all_features:\n",
    "        if feature_name in good_features[:FEATURE_COUNT]:\n",
    "            x_out.append(line[feature_num])\n",
    "        feature_num += 1\n",
    "    X_selected_train.append(x_out)\n",
    "\n",
    "X_selected_test = []\n",
    "for line in X_test:\n",
    "    x_out = []\n",
    "    feature_num = 0\n",
    "    for feature_name in all_features:\n",
    "        if feature_name in good_features[:FEATURE_COUNT]:\n",
    "            x_out.append(line[feature_num])\n",
    "        feature_num += 1\n",
    "    X_selected_test.append(x_out)\n",
    "    \n",
    "clf_select = linear_model.LinearRegression()\n",
    "#print 'Len1 %d' % len(X_selected)\n",
    "clf_select.fit (X_selected_train, y_train)\n",
    "print('R^2 selected train linear score: %.2f' % clf_select.score(X_selected_train, y_train))\n",
    "print('R^2 selected test linear score: %.2f' % clf_select.score(X_selected_test, y_test))\n",
    "\n",
    "    \n",
    "# SCALE it\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "print('R^2 test scaled linear score: %.2f' % clf.score(X_test_scaled, y_test))\n",
    "\n",
    "X_train_select_scaled = scaler.fit_transform(X_selected_train)\n",
    "X_test_select_scaled = scaler.fit_transform(X_selected_test)\n",
    "\n",
    "\n",
    "clf_select_scaled = linear_model.LinearRegression()\n",
    "clf_select_scaled.fit(X_train_select_scaled, y_train)\n",
    "print('R^2 test select scaled linear score: %.2f' % clf_select_scaled.score(X_test_select_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
